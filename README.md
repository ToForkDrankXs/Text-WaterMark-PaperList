# Text-WaterMark-PaperList

Text watermark is an important research direction for the misuse of LLM-generated text.
This repo will have the followings:

- [Text-WaterMark-PaperList](#text-watermark-paperlist)
- [1.BackGround](#1background)
  - [1.1 Application](#11-application)
  - [1.2 Classification](#12-classification)
    - [1.2.1 Bit Count](#121-bit-count)
    - [1.2.2 Embedding Phase](#122-embedding-phase)
    - [1.2.3 Generating-Process](#123-generating-process)
    - [1.2.4 Token-Level](#124-token-level)
    - [1.2.5 Different Scenarios](#125-different-scenarios)
  - [1.3 Necessary Features](#13-necessary-features)
  - [1.4 Attack Function](#14-attack-function)
    - [1.4.1 Word Level](#141-word-level)
    - [1.4.2 Sentence Level](#142-sentence-level)
    - [1.4.3 Spoof Attack](#143-spoof-attack)
- [2.Watermark Paper](#2watermark-paper)
- [3.Survey And Benchmark](#3survey-and-benchmark)
- [4.Attack](#4attack)
- [5.Other Research](#5other-research)
- [Reference](#reference)

# 1.BackGround

## 1.1 Application

* Deep Fake Detection: Detect whether the target text is generated by a language model;
* Deep Fake Attribution: Determine which model/user generated the target text;
* IP Protection: Protect valuable text and model

## 1.2 Classification

* [Bit Count](#121-bit-count)
  * Zero-Bit
  * Multi-Bit
* [Embedding Phase](#122-embedding-phase)
  * Backdoor/A-Priori
  * [Generating-Process](#123-generating-embedding-phase)
    * [Token Level](#124-token-level)
      * Logits Bias
      * Reweighting
      * Sampling
    * Sentence Level
  * Post-Hoc
* [Different-Scenarios](#125-different-scenarios)
  * Competion
  * Condition
  * Code

### 1.2.1 Bit Count

Distinguished based on the amount of information that can be embedded in the watermark.

* **Zero-Bit**: Only determine whether to add watermark, no additional information. This makes the watermark only detect, no attribution effect.
* **Multi-Bit**: Embed and extract multi-bit information, you can freely add the content you want to embed, such as time, user ID, etc. Multi-Bit watermark is necessary for deep fake attribution.

### 1.2.2 Embedding Phase

Text watermark research existed in the last century, at which time it was only possible to add watermarks to already written text, and was classified as Post-hoc. However, with the development of language models, some new stages of text watermark emerges.

* **Backdoor/A-Priori**: By employing specific methods to utilize watermark information to form a toxic dataset, fine-tuning or training a language model can result in *a language model with watermark*. The introduction of watermark information occurs *before the language model generates text*.
* **Generating-Process**: The introduction of watermark information will interfere with the generation process of the language model, resulting in the language model producing text with embedded watermarks. The addition of such watermarks does not require modification of the language model, but it necessitates access to the complete language model.
* **Post-Hoc**: By altering the text to introduce watermark information, the watermarked text is constructed. This kind of method does not require the original generative language model; it only requires the text generated by the model.

### 1.2.3 Generating-Process

This category represents a further subdivision within Category [Embedding Phase→Generating-Process](#122-embedding-phase).

* **Token-Level**: Watermark information is introduced when the language model generates a token each time.
* **Sentence-Level**: The embedding of watermark information is used when the language model generates each sentence. This requires a semi-controlled sampling process when generating: 1.No constraint is imposed until a sentence is generated; 2.Multiple candidates must be obtained using beam search during generation; 3.When generated, it must be generated sentence by sentence.

### 1.2.4 Token-Level

This category represents a further subdivision within Category [Embedding Phase→Generating-Process→Token-Level](#123-generating-process).

During each step of token generation, the language model undergoes the following processing:
Get **Logits** on the vocabulary $\\rightarrow$ Get Probability Distribution(**Weight**) over the vocabulary $\\rightarrow$ **Sample** from the probability distribution

* **Logits Bias**: The watermark information is converted into a logits distribution on the vocabulary, which is added to the logits distribution generated by the original language model to interfere with the generation phase.
* **Reweighting**: The watermark information will guide reweighting probability distribution. This typically involves scrambling the vocabulary and selecting a re-weighting interval.
* **Sampling**: Watermark information is embedded by influencing the generation results through sampling, which prohibits the commonly used decoding methods and restricts the decoding approach.

### 1.2.5 Different Scenarios

* **Completion**: Normal Generation. Given a prompt and complete it. Most watermarks are configured for this type of scenario.
* **Condition**: Conditional text generation. Such tasks are typically in the form of question-and-answer (QA) and summarization tasks.
* **Code**: Code generation. Generating executable code.

## 1.3 Necessary Features

The addition of watermarks often involves a trade-off among multiple aspects.

* **Detectability**: Detectability refers to the capability of a watermarking method to distinguish between watermarked text and non-watermarked text.
  Metric: Typically, it is a binary classification metric, and in the case of multiple bits, there are corresponding multi-bit comparison metrics.
  * TPR/TNR/FPR/FNR
  * AUROC
  * Accuracy
  * TPR@FPR=X%
  * Bit Accuracy/Bit Error Rate(Multi-Bit)
* **Invisibility/Text Quality**: Invisibility refers to the impact of the watermark on the quality of the generated text.
  Metric: Typically, the text quality metrics of the original generated text and the watermarked text are compared.
  * Perplexity(PPL)
  * BLEU
  * ROUGE(-n)
  * BERTScore
  * Entailment Score(ES)
  * Sentence Similarity
  * Human Evaluate
  * Ent-3[^Ent3]
  * Rep-3[^Rep3]
* **Imperceptibility**: Imperceptibility indicates the impact of watermark addition on the overall token distribution, focusing more on the statistical differences between watermarked and non-watermarked texts, which requires a large amount of corresponding text for overall estimation.
  Metric: Imperceptibility-related metrics often involve token-level statistics for the overall generated text. It assesses whether there are differences in the token distribution between watermarked texts and non-watermarked texts.
  * Word Frequency
* **Robustness**: Robustness refers to the ability of watermarked text to still be recognized as watermarked after undergoing watermark removal attacks.
  Metric: Robustness-related metrics are represented by comparing the changes in detectability indicators caused by attacks.
* **Usability**: Usability refers to the additional time and memory consumption caused by the addition of watermarks. These costs must be within an acceptable range for the user.
  Metric: Usability metrics typically consist of corresponding values for watermarking time and memory usage.
  * Time Cost
  * Memory Cost

## 1.4 Attack Function

### 1.4.1 Word Level

The watermark is removed by modifying the word.

* **Insert**: Insert words randomly according to proportion.
* **Delete**: Delete words randomly according to proportion.
* **Exchange**: Swap the positions of two words in a sentence.
* **Replace**: Similar substitutions are usually chosen based on the semantics of a particular word.
  * **Synonym**: Choose word substitutes according to the calculated thesaurus or the trained word vector.
  * **Context**: According to the MLM task of Masked Language Model, candidate words are determined by context.
* **Emoji**: The model is induced to insert emojis according to certain rules.
* **Exception Word Removal**: ONION, In the inference stage, GPT-2 pre-trained model is used to prevent the activation of backdoors by detecting and removing abnormal words such as "cf" in test samples.
* **HELM Perturbation**: Deliberately use word variations to remove watermarks.
  * **Structure**: do not --> don't
  * **Case**: Large --> large
  * **Spell/Ghost-Word**: sun --> sunn; sun --> san

### 1.4.2 Sentence Level

The watermark is removed by modifying the sentence.

* **Human-Modify**: Humans manually modify it directly.
* **Paraphrase**: Use language models to rewrite sentences. Model: DIPPER;pegasus_paraphrase...
  * Bigram-Paraphrase[^BiParaphrase]: When overwriting, several candidates are generated and the candidate with the least overlap of tokens is selected.
* **Back-Translate**: Translate into another language, translate back.
* **Re-Watermark**: Re-add watermark when overwriting.

### 1.4.3 Spoof Attack

The method of cracking the watermark is to try to forge the watermark text in a certain way.

# 2.Watermark Paper

About Key Word:

* The keywords we set are used to describe the most prominent features of the corresponding paper, the absence of some keywords does not mean that the paper does not cover those aspects.
  For example:Zero-Bit, Completion, Detectability, Logits Bias, Token Level.
* Some watermark already have classic abbreviations, which we have also included in the keywords.

- **[A watermark for large language models](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)**
  - **Proceedings / Journal-Year**: ICML-2023
  - **Key Word**: Zero-Bit,Logits Bias,KGW
  - **Note**: The classical method uses watermark information to divide the vocabulary into red and green list, and increases the logits of the green list.
  - **Code**: <https://github.com/jwkirchenbauer/lm-watermarking>

- **[Protecting Intellectual Property of Language Generation APIs with Lexical Watermark.](https://ojs.aaai.org/index.php/AAAI/article/view/21321)**
  - **Proceedings / Journal-Year**: AAAI-2022
  - **Key Word**: Post-Hoc, Lexical
  - **Note**: Lexical substitute
  - **Code**: <https://github.com/xlhex/NLG_api_watermark.git>
- **[CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks.](https://proceedings.neurips.cc/paper_files/paper/2022/file/2433fec2144ccf5fea1c9c5ebdbc3924-Paper-Conference.pdf)**
  - **Proceedings / Journal-Year**: NeurIPS-2022
  - **Key Word**: Post-Hoc, Condition
  - **Note**: Imporve-[Protecting Intellectual Property of Language Generation APIs with Lexical Watermark.](https://ojs.aaai.org/index.php/AAAI/article/view/21321)
  - **Code**: <https://github.com/xlhex/cater_neurips>

- **[Adversarial Watermarking Transformer: Towards Tracing Text Provenance with Data Hiding.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9519400)**
  - **Proceedings / Journal-Year**: SP-2021
  - **Key Word**: AWT, Multi-Bit, Post-Hoc
  - **Note**: Train watermark encoder and decoder, embed and extract watermark to exist text.
  - **Code**: <https://github.com/salesforce/awd-lstm-lm>

- **[Protecting Language Generation Models via Invisible Watermarking](https://proceedings.mlr.press/v202/zhao23i/zhao23i.pdf)**
  - **Proceedings / Journal-Year**: ICML-2023
  - **Key Word**: Reweighting
  - **Note**: -
  - **Code**: <https://github.com/XuandongZhao/Ginsew>

- **[Watermarking Pre-trained Language Models with Backdooring](https://arxiv.org/pdf/2210.07543)**
  - **Proceedings / Journal-Year**: 2022
  - **Key Word**: Backdoor
  - **Note**: -
  - **Code**: -
- **[DeepTextMark Deep Learning based Text Watermarking for Detection of Large Language Model Generated Text](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10471537)**
  - **Proceedings / Journal-Year**: IEEE-2024
  - **Key Word**: Post-Hoc
  - **Note**: Word substitute and candidate sentence selection
  - **Code**: -

- **[Tracing Text Provenance via Context-Aware Lexical Substitution](https://ojs.aaai.org/index.php/AAAI/article/view/21415)**
  - **Proceedings / Journal-Year**: AAAI-2022
  - **Key Word**: Post-Hoc, Multi-Bit
  - **Note**: Choose candidate word position and use Bert to choose words.
  - **Code**: -

- **[Towards Tracing Code Provenance with Code Watermarking](https://arxiv.org/pdf/2305.12461)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Code, Post-Hoc
  - **Note**: -
  - **Code**: -

- **[Watermarking Text Generated by Black-Box Language Models](https://arxiv.org/pdf/2305.08883)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Post-Hoc
  - **Note**: MLM generates candidate words and scores candidate sentences
  - **Code**: <https://github.com/Kiode/Text_Watermark>

- **[Who Wrote this Code? Watermarking for Code Generation](https://arxiv.org/pdf/2305.15060)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: SWEET, Logits Bias, Code, Invisibility
  - **Note**: Use entropy threshold to control logits bias. Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://github.com/hongcheki/sweet-watermark>

- **[Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark](https://arxiv.org/pdf/2305.10036)**
  - **Proceedings / Journal-Year**: ACL-2023
  - **Key Word**: Backdoor
  - **Note**: -
  - **Code**: <https://github.com/yjw1029/EmbMarker>
- **[Robust Multi-bit Natural Language Watermarking through Invariant Features](https://aclanthology.org/2023.acl-long.117.pdf)**
  - **Proceedings / Journal-Year**: ACL-2023
  - **Key Word**: Post-Hoc, Multi-Bit
  - **Note**: MLM generate candidate words, Select the candidate at the corresponding position to correspond to the watermark information
  - **Code**: <https://github.com/bangawayoo/nlp-watermarking>

- **[Undetectable Watermarks for Language Models](https://arxiv.org/pdf/2306.09194)**
  - **Proceedings / Journal-Year**: IACR-2023
  - **Key Word**: Sample
  - **Note**: The embedding process of watermark is controlled by entropy
  - **Code**: -

- **[Robust Distortion-free Watermarks for Language Models](https://arxiv.org/pdf/2307.15593)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Sample, EXP, EXP-Edit
  - **Note**: The sampling related parameters are generated by the secret key sequence to interfere with the sampling
  - **Code**: <https://github.com/jthickstun/watermark>

- **[SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation](https://aclanthology.org/2024.naacl-long.226.pdf)**
  - **Proceedings / Journal-Year**: NAACL-2024
  - **Key Word**: Sentence-Level, Semstamp
  - **Note**: Sentence level red/green list. Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://github.com/bohanhou14/SemStamp>

- **[Three Bricks to Consolidate Watermarks for Large Language Models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10374576&tag=1)**
  - **Proceedings / Journal-Year**: WIFS-2023
  - **Key Word**: Logits-Bias, Detectability
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Change the detection method to improve the relative detection accuracy
  - **Code**: -
- **[PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification](https://arxiv.org/pdf/2308.02816)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Backdoor, PromptCARE
  - **Note**: For prompt as a service
  - **Code**: -
- **[Embarrassingly Simple Text Watermarks](https://arxiv.org/pdf/2310.08920)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Post-Hoc
  - **Note**: Add watermark with invisible/similar Unicode characters
  - **Code**: [Not Code]<https://easymarkdemo.github.io/>

- **[Publicly Detectable Watermarking for Language Models](https://arxiv.org/pdf/2310.18491)**
  - **Proceedings / Journal-Year**: IACR-2023
  - **Key Word**: Sample
  - **Note**: A relatively complicated method
  - **Code**: <https://github.com/jfairoze/publicly-detectable-watermark>

- **[Improving the Generation Quality of Watermarked Large Language Models via Word Importance Scoring](https://arxiv.org/pdf/2311.09668)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Logits-Bias, Invisibility
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Generate a score for each step to determine whether to add a watermark
  - **Code**: -

- **[WatME: Towards Lossless Watermarking Through Lexical Redundancy](https://arxiv.org/pdf/2311.09832)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Logits-Bias, Invisibility
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Use synonyms to interfere with the red-green list division
  - **Code**: <https://github.com/ChanLiang/WatME>

- **[Necessary and sufficient watermark for large language models.](https://arxiv.org/pdf/2310.00833)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Sample, Invisibility
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), By controlling the proportion of green tokens, the text quality can be improved while the detection performance is guaranteed
  - **Code**: -
- **[Provable robust watermarking for ai-generated text.](https://arxiv.org/pdf/2306.17439)**
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: Logits-Bias, Invisibility, Robustness, Detectability, Usability, Unigram
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Fixed red-green list for better performance
  - **Code**: <https://github.com/XuandongZhao/Unigram-Watermark>

- **[Watermarking conditional text generation for ai detection: Unveiling challenges and a semantic-aware watermark remedy.](https://ojs.aaai.org/index.php/AAAI/article/view/29756)**
  - **Proceedings / Journal-Year**: AAAI-2024
  - **Key Word**: Logits-Bias, Invisibility, Condition
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Use semantics to divide red and green lists to improve text quality
  - **Code**: -

- **[A Semantic Invariant Robust Watermark for Large Language Models](https://arxiv.org/pdf/2310.06356)**
  - **Proceedings / Journal-Year**: ICLR-2024
  - **Key Word**: Logits-Bias, Robustness, Invisibility, Imperceptibility, SIR
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Generate a logits bias based on semantics to add a watermark
  - **Code**: <https://github.com/THU-BPM/Robust_Watermark>

- **[Towards Optimal Statistical Watermarking](https://arxiv.org/pdf/2312.07930)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Generating-Process, UMP
  - **Note**: The statistical value of watermark judgment is controlled to achieve the best effect
  - **Code**: -

- **[REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models](https://arxiv.org/pdf/2310.12362)**
  - **Proceedings / Journal-Year**: USENIX-2023
  - **Key Word**: Sample, Logits-Bias, Multi-Bit
  - **Note**: -
  - **Code**: -

- **[Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark](https://arxiv.org/pdf/2402.14007)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Logits-Bias, Detectability
  - **Note**: This paper aims at the problem that the watermark strength decreases when the text in A language is translated into B language. Improve-[SIR](https://arxiv.org/pdf/2310.06356)
  - **Code**: [https://github.com/zwhe99/X-SI](https://github.com/zwhe99/X-SIR)
- **[k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text](https://arxiv.org/pdf/2402.11399)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sentence-Level, k-SemStamp
  - **Note**: Improve-[SemStamp](https://aclanthology.org/2024.naacl-long.226.pdf)
  - **Code**: <https://github.com/bohanhou14/SemStamp>

- **[Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models](https://arxiv.org/pdf/2402.18059)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Logits-Bias
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Dynamically adjust the hyperparameters at generation time
  - **Code**: <https://github.com/mignonjia/TS_watermark>

- **[WaterMax: breaking the LLM watermark detectability-robustness-quality](https://arxiv.org/pdf/2403.04808)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample
  - **Note**: Select text with a high watermark score using beam search
  - **Code**: -

- **[Adaptive Text Watermark for Large Language Models](https://arxiv.org/pdf/2401.13927)**
  - **Proceedings / Journal-Year**: ICML-2024
  - **Key Word**: Logits-Bias, Invisibility
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Similar to [SIR](https://arxiv.org/pdf/2310.06356). Use the model to determine logits bias
  - **Code**: <https://github.com/yepengliu/adaptive-text-watermark>

- **[Cross-Attention Watermarking of Large Language Models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10446397)**
  - **Proceedings / Journal-Year**: ICASSP-2024
  - **Key Word**: Post-Hoc, Multi-Bit
  - **Note**: Improve-[AWT](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9519400)
  - **Code**: <https://gitlab.com/folbaeni/linguistic-watermark>
- **[Multi-Bit Distortion-Free Watermarking for Large Language Models](https://arxiv.org/pdf/2402.16578)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample, Multi-Bit
  - **Note**: Improve-[Undetectable Watermarks for Language Models](https://arxiv.org/pdf/2306.09194)
  - **Code**: -

- **[An Unforgeable Publicly Verifiable Watermark for Large Language Models](https://openreview.net/pdf?id=gMLQwKDY3N)**
  - **Proceedings / Journal-Year**: ICLR-2024
  - **Key Word**: Logits-Bias, UPV
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://github.com/THU-BPM/unforgeable_watermark>

- **[A Resilient and Accessible Distribution-Preserving Watermark for Large Language Models](https://arxiv.org/pdf/2310.07710)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Logits-Bias, DiPmark
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://github.com/yihwu/DiPmark>

- **[Towards Codable Watermarking for Injecting Multi-bit Information to LLM](https://arxiv.org/pdf/2307.15992)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Multi-Bit, Logits-Bias
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://github.com/lancopku/codable-watermarking-for-llm>

- **[Resilient Watermarking for LLM-Generated Codes](https://arxiv.org/pdf/2402.07518)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Post-Hoc, Code, ACW
  - **Note**: -
  - **Code**: <https://github.com/boutiquelee/ACW>

- **[Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs](https://arxiv.org/pdf/2402.05864)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample
  - **Note**: -
  - **Code**: <https://github.com/XuandongZhao/pf-decoding>

- **Not Paper**: <https://simons.berkeley.edu/talks/scott-aaronson-ut-austin-openai-2023-08-17>
  - **Proceedings / Journal-Year**: 2023
  - **Key Word**: AAR
  - **Note**: -
  - **Code**: -

- **[An Entropy-based Text Watermarking Detection Method](https://arxiv.org/pdf/2403.13485)**
  - **Proceedings / Journal-Year**: ACL-2024
  - **Key Word**: Sample, Condition
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), The score of detection is determined dynamically according to entropy
  - **Code**: <https://github.com/luyijian3/EWD>
- **[Duwak: Dual Watermarks in Large Language Models](https://arxiv.org/pdf/2403.13000)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample, Logits-Bias
  - **Note**: double watermark, Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Improve-[EXP](https://arxiv.org/pdf/2307.15593)
  - **Code**: -

- **[Is Watermarking LLM-Generated Code Robust?](https://openreview.net/pdf?id=8PhI1PzSYY)**
  - **Proceedings / Journal-Year**: ICLR-2024
  - **Key Word**: Code, Post-Hoc
  - **Note**: -
  - **Code**: [https://github.com/uiuc-arc/llm-code-watermark](https://github.com/uiuc-arc/llm-code-watermark)

- **[Learning to Watermark LLM-generated Text via Reinforcement Learning](https://arxiv.org/pdf/2403.10553)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Backdoor
  - **Note**: Use reinforcement learning to quickly embed backdoors
  - **Code**: <https://github.com/xiaojunxu/learning-to-watermark-llm>

- **[Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning](https://arxiv.org/pdf/2402.14883)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Backdoor
  - **Note**: -
  - **Code**: -

- **[Stylometric Watermarks for Large Language Models](https://arxiv.org/pdf/2405.08400)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample, Logits-Bias
  - **Note**: -
  - **Code**: -

- **[Watermarking Language Models for Many Adaptive Users](https://eprint.iacr.org/2024/759.pdf)**
  - **Proceedings / Journal-Year**: IACR-2024
  - **Key Word**: Multi-Bit
  - **Note**: -
  - **Code**: -

- **[Injecting Undetectable Backdoors in Deep Learning and Language Models](https://arxiv.org/pdf/2406.05660)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Backdoor
  - **Note**: -
  - **Code**: -

- **[Bileve: Securing Text Provenance in Large Language Models Against Spoofing with Bi-level Signature](https://arxiv.org/pdf/2406.01946)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample, Multi-Bit
  - **Note**: -
  - **Code**: -

- **[Large Language Models as Carriers of Hidden Messages](https://arxiv.org/pdf/2406.02481)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Backdoor
  - **Note**: -
  - **Code**: [https://github.com/j-hoscilowic/zurek-stegano](https://github.com/j-hoscilowic/zurek-stegano)
- **[Watermarking Counterfactual Explanations](https://arxiv.org/pdf/2405.18671)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Backdoor, A-Prior
  - **Note**: -
  - **Code**: <https://github.com/BirkhoffG/CFMark>

- **[A Watermark for Low-entropy and Unbiased Generation in Large Language Models](https://arxiv.org/pdf/2405.14604)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample
  - **Note**: -
  - **Code**: <https://github.com/djwei96/STA>

- **[WaterPool: A Watermark Mitigating Trade-offs among Imperceptibility, Efficacy and Robustness](https://arxiv.org/pdf/2405.13517)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Multi-Watermark
  - **Note**: Use semantic mapping for different keys
  - **Code**: -

- **[Waterfall: Framework for Robust and Scalable Text Watermarking](https://arxiv.org/pdf/2407.04411)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Post-Hoc
  - **Note**: Related methods of implementing generative watermarking by using rewriter
  - **Code**: -

- **[Less is More: Sparse Watermarking in LLMs with Enhanced Text Quality](https://arxiv.org/pdf/2407.13803)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Logits-Bias, Invisibility
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://github.com/mail-research/sparse-llm-watermarking/>

- **[Advancing beyond identification: Multi-bit watermark for large language models.](https://aclanthology.org/2024.naacl-long.224.pdf)**
  - **Proceedings / Journal-Year**: NAACL-2024
  - **Key Word**: Multi-Bit, Logits-Bias, MPAC
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://github.com/bangawayoo/mb-lm-watermarking>

- **[MCGMark: An Encodable and Robust Online Watermark for LLM-Generated Malicious Code](https://arxiv.org/pdf/2408.01354)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Code, Sample, Logits-Bias
  - **Note**: -
  - **Code**: -
- **[Hey, That's My Model! Introducing Chain&Hash, An LLM Fingerprinting Technique](https://arxiv.org/pdf/2407.10887)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Backdoor
  - **Note**: -
  - **Code**: -

- **[PostMark: A Robust Blackbox Watermark for Large Language Models](https://arxiv.org/pdf/2406.14517)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Post-Hoc
  - **Note**: paraphrase, watermark word list selection
  - **Code**: <https://github.com/lilakk/PostMark>

- **[Adaptive and robust watermark against model extraction attack](https://arxiv.org/pdf/2405.02365)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Generating-Process
  - **Note**: prompt to insert watermark words
  - **Code**: <https://github.com/amaoku/ModelShield>

- **[Provably Robust Multi-bit Watermarking for AI-generated Text](https://arxiv.org/abs/2401.16820)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Multi-Bit
  - **Note**: Corrected coding
  - **Code**: <https://github.com/randomizedtree/segment-watermark>

- **[GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick](https://aclanthology.org/2024.acl-long.315.pdf)**
  - **Proceedings / Journal-Year**: ACL-2024
  - **Key Word**: Generating-Process
  - **Note**: Gumbel-Softmax
  - **Code**: [https://github.com/PorUna-byte/Gumbelsoft](https://github.com/PorUna-byte/Gumbelsoft)

- **[PersonaMark: Personalized LLM watermarking for model protection and user attribution](https://arxiv.org/pdf/2409.09739)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sentence-Level, Generating-Process
  - **Note**: Sentence syntax structure mapping, Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: -

- **[A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://aclanthology.org/2024.findings-naacl.40.pdf)**
  - **Proceedings / Journal-Year**: NAACL-2024
  - **Key Word**: Generating-Process
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), map seed by semantic
  - **Code**: [https://github.com/renjie3/SemaMark](https://github.com/renjie3/SemaMark)

- **[A Watermark for Order-Agnostic Language Models](https://arxiv.org/pdf/2410.13805)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Generating-Process, Logits-Bias
  - **Note**: order-agnostic LM watermark
  - **Code**: -

- **[Signal Watermark on Large Language Models](https://arxiv.org/pdf/2410.06545)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample
  - **Note**: Signal sample, Reduces the diversity of the generated text
  - **Code**: -

- **[Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice](https://arxiv.org/pdf/2410.02890)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Generating-Process, Logits-Bias
  - **Note**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), a frame.
  - **Code**: -

- **[A Watermark for Black-Box Language Models](https://arxiv.org/pdf/2410.02099)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Generating-Process, Sentence-Level
  - **Note**: regenrating, select high score sentence
  - **Code**: -

- **[A Certified Robust Watermark For Large Language Models](https://arxiv.org/pdf/2409.19708)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Generating-Process, Logits-Bias
  - **Note**: Improving-[UPV](https://openreview.net/pdf?id=gMLQwKDY3N)
  - **Code**: -

- **[Provably Robust Watermarks for Open-Source Language Models](https://eprint.iacr.org/2024/1739.pdf)**
  - **Proceedings / Journal-Year**: 2024-IACR
  - **Key Word**: Generating-Process
  - **Note**: Improving-KGW
  - **Code**: -

- **[Scalable watermarking for identifying large language model outputs](https://www.nature.com/articles/s41586-024-08025-4)**
  - **Proceedings / Journal-Year**: 2024-Nature
  - **Key Word**: Sampling
  - **Note**: Slike window, context history, tournament sampling approach
  - **Code**: <https://github.com/google-deepmind/synthid-text/tree/main>

- **[Watermarking Language Models through Language Models](https://arxiv.org/abs/2411.05091)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Prompt
  - **Note**: prompt to add watermark
  - **Code**: -

- **[Debiasing Watermarks for Large Language Models via Maximal Coupling](https://arxiv.org/pdf/2411.11203)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Sample
  - **Note**: Improving-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), unbiased by change decoding method
  - **Code**: <https://github.com/Xieyangxinyu/Debiasing-Watermarks-for-Large-Language-Models-via-Maximal-Coupling>

- **[Segmenting Watermarked Texts From Language Models](https://papers.nips.cc/paper_files/paper/2024/file/1a8d295871250443f9747d239925b89d-Paper-Conference.pdf)**
  - **Proceedings / Journal-Year**: NeurIPS-2024
  - **Key Word**: Sample
  - **Note**: Improving EXP, Gumbel, check watermark text in segment
  - **Code**: <https://github.com/doccstat/llm-watermark-cpd>

- **[TREND: A Whitespace Replacement Information Hiding Method](https://arxiv.org/pdf/2502.12710)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Post-Hoc, Lexical
  - **Note**: replace white space
  - **Code**: <https://github.com/FraunhoferISST/Innamark>

- **[DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models](https://arxiv.org/pdf/2502.05213)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Multi-Bit
  - **Note**: Dynamic segment text to detect multi-bit watermark, use KGW scheme
  - **Code**: -

- **[Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign](https://arxiv.org/pdf/2502.02068)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Post-Hoc
  - **Note**: Training to rewrite code
  - **Code**: -

- **[BiMarker: Enhancing Text Watermark Detection for Large Language Models with Bipolar Watermarks](https://arxiv.org/pdf/2501.12174)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Logits-Biased
  - **Note**: Improving-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: -

- **[Robust Multi-bit Text Watermark with LLM-based Paraphrasers](https://arxiv.org/pdf/2412.03123)**
  - **Proceedings / Journal-Year**: 2024
  - **Key Word**: Post-Hoc, sentence level, multi-bit
  - **Note**: paraphraser to encode watermark to text
  - **Code**: <https://github.com/xiaojunxu/multi-bit-text-watermark>

- **[Srcmarker: Dualchannel source code watermarking via scalable code transformations](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10646683)**
  - **Proceedings / Journal-Year**: 2024-SP
  - **Key Word**: Code, Post-hoc
  - **Note**: Transform code by the defined table
  - **Code**: <https://github.com/YBRua/SrcMarker>

- **[Domain Watermark: Effective and Harmless Dataset Copyright Protection is Closed at Hand](https://proceedings.neurips.cc/paper_files/paper/2023/file/aa6287ca31ae1474ea802342d0c8ba63-Paper-Conference.pdf)**
  - **Proceedings / Journal-Year**: 2023-NeurIPS
  - **Key Word**: Backdoor
  - **Note**: Protect dataset
  - **Code**: <https://github.com/JunfengGo/Domain-Watermark>

- **[Robust Steganography from Large Language Models](https://arxiv.org/pdf/2504.08977)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Generating, Logits-Bias
  - **Note**: Theory Prove
  - **Code**: <https://github.com/NeilAPerry/robust_steganography>

- **[Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning](https://arxiv.org/pdf/2504.06575)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Post-Hoc, Sentence Level
  - **Note**: Improving-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), against to generate toxic text
  - **Code**: <https://github.com/UCSB-NLP-Chang/contrastive-watermark>

- **[Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking](https://arxiv.org/pdf/2503.04636)**
  - **Proceedings / Journal-Year**: 2025-ICLR Workshop
  - **Key Word**: Backdoor
  - **Note**: Comprehensive evaluation in Open-LLM
  - **Code**: -

- **[Enhancing Watermarking Quality for LLMs via Contextual Generation States Awareness](https://arxiv.org/pdf/2506.07403)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Decoding
  - **Note**: contextual indicates generation
  - **Code**: -

- **[In-Context Watermarks for Large Language Models](https://arxiv.org/pdf/2505.16934)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Prompt
  - **Note**: -
  - **Code**: -

- **[Robust LLM Fingerprinting via Domain-Specific Watermarks](https://arxiv.org/pdf/2505.16723)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Backdoor
  - **Note**: -
  - **Code**: [https://github.com/eth-sri/robust-llm-fingerprints](https://github.com/eth-sri/robust-llm-fingerprints)

- **[Optimized Couplings for Watermarking Large Language Models](https://arxiv.org/pdf/2505.08878)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Reweighting
  - **Note**: scale logits
  - **Code**: <https://github.com/Carol-Long/CC_Watermark>

- **[An End-to-End Model for Logits Based Large Language Models Watermarking](https://arxiv.org/pdf/2505.02344)**
  - **Proceedings / Journal-Year**: ICML-2025
  - **Key Word**: Logits-Biased
  - **Note**: (空)
  - **Code**: <https://github.com/KAHIMWONG/E2E-LLM-Watermark>

- **[Towards the Resistance of Neural Network Watermarking to Fine-tuning](https://arxiv.org/pdf/2505.01007)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: A-priori
  - **Note**: (空)
  - **Code**: -

- **[LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps](https://arxiv.org/abs/2505.01484)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Logits-Biased
  - **Note**: (空)
  - **Code**: -

- **[Reversible natural language watermarking with augmented word prediction and compression](https://www.sciencedirect.com/science/article/pii/S2214212625002480)**
  - **Proceedings / Journal-Year**: JISA-2025
  - **Key Word**: Multi-Bit, Post-hoc
  - **Note**: (空)
  - **Code**: -

- **[Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm](https://arxiv.org/pdf/2509.07287)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Backdoor
  - **Note**: (空)
  - **Code**: -

- **[Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Logits-Bias
  - **Note**: imporve SynthID
  - **Code**: <https://github.com/githshine/SynGuard>

- **[Optimizing Token Choice for Code Watermarking: A RL Approach](https://arxiv.org/abs/2508.11925)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Logits-Bias, Code
  - **Note**: RL for KGW
  - **Code**: -

- **[SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling](https://arxiv.org/pdf/2508.08211)**
  - **Proceedings / Journal-Year**: 2025
  - **Key Word**: Multi-Bit, Post-Hoc
  - **Note**: Batch process to advance watermark detection
  - **Code**: -

- **[LOCAT: Localization-Driven Text Watermarking via Large Language Models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11006126)**
  - **Proceedings / Journal-Year**: TCS-2025
  - **Key Word**: Post-Hoc, Multi-Bit
  - **Note**: Only test Post-Hoc wm
  - **Code**: -

- **[CurveMark: Detecting AI-Generated Text via Probabilistic Curvature and Dynamic Semantic Watermarking](https://www.mdpi.com/1099-4300/27/8/784)**
  - **Proceedings / Journal-Year**: Entropy-2025
  - **Key Word**: Logits-Bias
  - **Note**: Detection Framework and Semantic R-G List
  - **Code**: -


# 3.Survey And Benchmark

- **[A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions]()**
  - **Proceedings / Journal-Year**: 2024
  - **Type**: Survey

- **[A Survey of Text Watermarking in the Era of Large Language Models](https://arxiv.org/pdf/2312.07913)**
  - **Proceedings / Journal-Year**: 2024
  - **Type**: Survey

- **[Mark My Words: Analyzing and Evaluating Language Model Watermarks](https://arxiv.org/pdf/2312.00273)**
  - **Proceedings / Journal-Year**: 2023
  - **Type**: Benchmark

- **[Copyright Protection in Generative AI: A Technical Perspective](https://arxiv.org/pdf/2402.02333)**
  - **Proceedings / Journal-Year**: 2024
  - **Type**: Survey

- **[Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond](https://arxiv.org/pdf/2407.11100)**
  - **Proceedings / Journal-Year**: 2024
  - **Type**: Survey

- **[Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods](https://arxiv.org/pdf/2406.15583)**
  - **Proceedings / Journal-Year**: 2024
  - **Type**: Survey

- **[Securing Large Language Models: Addressing Bias, Misinformation, and Prompt Attacks](https://arxiv.org/pdf/2409.08087)**
  - **Proceedings / Journal-Year**: 2024
  - **Type**: Survey

- **[SoK: On the Role and Future of AIGC Watermarking in the Era of Gen-AI](https://arxiv.org/pdf/2411.11478)**
  - **Proceedings / Journal-Year**: 2024
  - **Type**: Survey

- **[The Imitation Game revisited: A comprehensive survey on recent advances in AI-generated text detection](https://www.sciencedirect.com/science/article/pii/S0957417425003161)**
  - **Proceedings / Journal-Year**: 2025
  - **Type**: Survey

# 4.Attack

In this part, the core of the paper is the research of the watermarking attack method, and sometimes the corresponding solution is proposed.

- **[On the Learnability of Watermarks for Language Models](https://arxiv.org/pdf/2312.04469)**
  - **Proceedings / Journal-Year**: ICLR-2024
  - **AttackType**: Spoof
  - **Note**: Two different distillation methods to learn watermarking information
  - **Code**: <https://github.com/chenchenygu/watermark-learnability>

- **[Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models](https://arxiv.org/pdf/2311.04378)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Paraphrase, Word Level
  - **Note**: A practical method to completely remove the watermark, but the complexity is relatively high
  - **Code**: <https://github.com/hlzhang109/impossibility-watermark>

- **[Watermark Stealing in Large Language Models](https://arxiv.org/pdf/2402.19361)**
  - **Proceedings / Journal-Year**: ICML-2024
  - **AttackType**: Spoof
  - **Note**: For-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Using n-gram score interference to imitate watermarking
  - **Code**: <https://github.com/eth-sri/watermark-stealing>

- **[Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense](https://arxiv.org/pdf/2303.13408)**
  - **Proceedings / Journal-Year**: NeurIPS-2024
  - **AttackType**: Paraphrase, DIPPER
  - **Note**: -
  - **Code**: <https://github.com/martiansideofthemoon/ai-detection-paraphrases>

- **[Can AI-Generated Text be Reliably Detected?](https://arxiv.org/pdf/2303.11156)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Spoof, Paraphrase
  - **Note**: The result of multiple detection methods under different attacks
  - **Code**: <https://github.com/vinusankars/Reliability-of-AI-text-detectors>

- **[Lost in Overlap: Exploring Watermark Collision in LLMs](https://arxiv.org/pdf/2403.10020)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Paraphrase
  - **Note**: -
  - **Code**: -

- **[Evading AI-Generated Content Detectors using Homoglyphs](https://arxiv.org/pdf/2406.11239)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Word Level
  - **Note**: Use homonyms to attack
  - **Code**: <https://github.com/ACMCMC/silverspeak>

- **[Large Language Model Watermark Stealing With Mixed Integer Programming](https://arxiv.org/pdf/2405.19677)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Spoof
  - **Note**: Find green list, For-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf)
  - **Code**: <https://anonymous.4open.science/r/mip_watermark_stealing-78C9>

- **[Alignment-Aware Model Extraction Attacks on Large Language Models](https://arxiv.org/pdf/2409.02718)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: -
  - **Note**: Remove Backdoor watermark
  - **Code**: -

- **[WAPITI: A Watermark for Finetuned Open-Source LLMs](https://arxiv.org/pdf/2410.06467)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Spoof
  - **Note**: a spoof attack for open LLM by parameter changing
  - **Code**: -

- **[Optimizing Adaptive Attacks against Content Watermarks for Language Models](https://arxiv.org/pdf/2410.02440)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Paraphrase
  - **Note**: how to fine-tune a language model to paraphrase
  - **Code**: <https://github.com/ML-Watermarking/ada-llm-wm>

- **[Revisiting the Robustness of Watermarking to Paraphrasing Attacks](https://aclanthology.org/2024.emnlp-main.1005.pdf)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Spoof
  - **Note**: inverse spoof attack to test robustness
  - **Code**: <https://github.com/codeboy5/revisiting-watermark-robustness>

- **[B4: A Black-Box Scrubbing Attack on LLM Watermarks](https://arxiv.org/pdf/2411.01222)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: Scrubbing
  - **Note**: Black-Box to scrub watermark
  - **Code**: -

- **[Bypassing LLM Watermarks with Color-Aware Substitutions](https://arxiv.org/pdf/2403.14719)**
  - **Proceedings / Journal-Year**: ACL-2024
  - **AttackType**: spoofing, scrubbing
  - **Note**: spoofing and scrubbing by green list predict with prompt
  - **Code**: -

- **[Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text](https://arxiv.org/pdf/2506.07001)**
  - **Proceedings / Journal-Year**: 2025
  - **AttackType**: scrubbing
  - **Note**: new paraphraser
  - **Code**: <https://github.com/chengez/Adversarial-Paraphrasin>

- **[Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org/pdf/2505.05190)**
  - **Proceedings / Journal-Year**: ICML-2025
  - **AttackType**: scrubbing
  - **Note**: Combine self-information to construct MLM and rewrite to attack
  - **Code**: <https://github.com/Allencheng97/Self-information-Rewrite-Attack>

- **[Character-Level Perturbations Disrupt LLM Watermarks](https://arxiv.org/pdf/2509.09112)**
  - **Proceedings / Journal-Year**: NDSS-2026
  - **AttackType**: scrubbing
  - **Note**: construct character-level attacks
  - **Code**: <https://github.com/plll4zzx/CharacterRemoval4WM>


# 5.Other Research

- **[Performance Trade-offs of Watermarking Large Language Models](https://arxiv.org/pdf/2311.09816)**
  - **Proceedings / Journal-Year**: 2023
  - **Detail**: Performance variation of [KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf) on different NLP tasks
  - **Code**: -

- **[New Evaluation Metrics Capture Quality Degradation due to LLM Watermarking](https://openreview.net/pdf?id=PuhF0hyDq1)**
  - **Proceedings / Journal-Year**: TMLR-2023
  - **Detail**: Evaluation Method
  - **Code**: <https://github.com/su-karanps/watermark_eval>

- **[Optimizing watermarks for large language models](https://arxiv.org/pdf/2312.17295)**
  - **Proceedings / Journal-Year**: 2023
  - **Detail**: Improve-[KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), Converting watermarking to optimization problem
  - **Code**: -

- **[Watermarking Makes Language Models Radioactive](https://arxiv.org/pdf/2402.14904)**
  - **Proceedings / Journal-Year**: 2024
  - **Detail**: Radioactive, Learnability about watermark. The main concern is whether the watermarked model output can affect the training model when it is used as training data
  - **Code**: -

- **[No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design Choices](https://arxiv.org/pdf/2402.16187)**  
  - **Proceedings / Journal-Year**: 2024  
  - **Detail**: Test about some watermarking attack methods.  
  - **Code**: -  

- **[Baselines for Identifying Watermarked Large Language Models](https://arxiv.org/pdf/2305.18456)**  
  - **Proceedings / Journal-Year**: 2023  
  - **Detail**: Identify whether the language model contains watermarks based on the output  
  - **Code**: -  

- **[WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models](https://arxiv.org/pdf/2403.19548)**  
  - **Proceedings / Journal-Year**: NAACL-2024  
  - **Detail**: A large number of experiments for [KGW](https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf), and a new evaluation method  
  - **Code**: -  

- **[A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](https://arxiv.org/pdf/2404.01245)**  
  - **Proceedings / Journal-Year**: 2024  
  - **Detail**: Watermark hyperparameter optimization framework  
  - **Code**: -  

- **[MARKLLM: An Open-Source Toolkit for LLM Watermarking](https://arxiv.org/pdf/2405.10051)**  
  - **Proceedings / Journal-Year**: 2024  
  - **Detail**: Watermarking integration tool  
  - **Code**: <https://github.com/THU-BPM/MarkLLM>  

- **[Black-Box Detection of Language Model Watermarks](https://arxiv.org/pdf/2405.20777)**  
  - **Proceedings / Journal-Year**: 2024  
  - **Detail**: Aiming at the popular watermarking methods, a black-box detection method is proposed  
  - **Code**: -  

- **[Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?](https://arxiv.org/pdf/2407.17417)**  
  - **Proceedings / Journal-Year**: 2024  
  - **Detail**: Aiming at the effect of watermarking on copyright data determination in training data, MIA attack is prevented  
  - **Code**: -  

- **[On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks](https://arxiv.org/pdf/2407.04794)**  
  - **Proceedings / Journal-Year**: 2024  
  - **Detail**: Evaluation of watermark comprehensive performance  
  - **Code**: -

- **[Red Teaming Language Model Detectors with Language Models](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00639/119629/Red-Teaming-Language-Model-Detectors-with-Language)**
  - **Proceedings / Journal-Year**: TACL-2024
  - **AttackType**: About attack on different detection methods, including watermark
  - **Note**: -
  - **Code**: <https://github.com/shizhouxing/LLM-Detector-Robustness>

- **[WaterSeeker: Efficient Detection of Watermarked Segments in Large Documents](https://arxiv.org/pdf/2409.05112)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: About detection in only part of watermark text in a document
  - **Note**: -
  - **Code**: <https://github.com/THU-BPM/WaterSeeker>

- **[Efficiently Identifying Watermarked Segments in Mixed-Source Texts](https://arxiv.org/pdf/2410.03600)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: improve detection in mixed-source texts
  - **Note**: -
  - **Code**: -

- **[Ward: Provable RAG Dataset Inference via LLM Watermarks](https://arxiv.org/pdf/2410.03537)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: watermark for RAG Dataset
  - **Note**: -
  - **Code**: -

- **[Discovering Clues of Spoofed LM Watermarks](https://arxiv.org/pdf/2410.02693)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: spoof analsys
  - **Note**: -
  - **Code**: -

- **[WaterPark: A Robustness Assessment of Language Model Watermarking](https://arxiv.org/pdf/2411.13425)**
  - **Proceedings / Journal-Year**: 2024
  - **AttackType**: comprehensive evaluation for robustness
  - **Note**: -
  - **Code**: <https://github.com/JACKPURCELL/sok-llm-watermark>

- **[Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models](https://papers.nips.cc/paper_files/paper/2024/file/6415b5dc9aa4bf4e6404cb221a109ec7-Paper-Conference.pdf)**
  - **Proceedings / Journal-Year**: NeurIPS-2024
  - **AttackType**: Trade-off between sample method efficiency and watermark
  - **Note**: -
  - **Code**: -

- **[Can Watermarked LLMs be Identified by Users via Crafted Prompts?](https://arxiv.org/pdf/2410.03168)**
  - **Proceedings / Journal-Year**: ICLR-2025
  - **AttackType**: Vertiy LLM with watermark by prompts
  - **Note**: -
  - **Code**: <https://github.com/THU-BPM/Watermarked_LLM_Identification>

- **[Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark](https://arxiv.org/pdf/2502.08332)**
  - **Proceedings / Journal-Year**: 2025
  - **AttackType**: change detect method, add unexpected tokens to filter
  - **Note**: -
  - **Code**: -

- **[Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking](https://aclanthology.org/2025.acl-long.1436.pdf)**
  - **Proceedings / Journal-Year**: ACL-2025
  - **AttackType**: research about attack, good evaluation
  - **Note**: -
  - **Code**: -

# Reference

[^Ent3]: [Generating informative and diverse conversational responses via adversarial information maximization.](https://proceedings.neurips.cc/paper_files/paper/2018/file/23ce1851341ec1fa9e0c259de10bf87c-Paper.pdf)

[^Rep3]: [Neural text generation with unlikelihood training](https://openreview.net/forum?id=SJeYe0NtvH)

[^BiParaphrase]: [SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation](https://aclanthology.org/2024.naacl-long.226.pdf)